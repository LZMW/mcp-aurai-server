# ========================================
# 上级AI MCP 服务器 - 环境变量配置示例
# ========================================
# 版本: v2.2.0
# 模型: 基于 GLM-4.7 参数优化

# ----------------------------------------
# 必填配置
# ----------------------------------------

# API密钥 - 从您的API提供商获取
AURAI_API_KEY=your-api-key-here

# API基础URL - OpenAI兼容API的地址
# 常用示例：
# - 智谱AI: https://open.bigmodel.cn/api/paas/v4/
# - DeepSeek: https://api.deepseek.com/v1
# - 其他中转站: https://your-proxy.com/v1
AURAI_BASE_URL=https://api.example.com/v1

# 模型名称 - 使用的模型
# 推荐使用 GLM-4.7 系列：glm-4.7, glm-4.7-flashx
AURAI_MODEL=glm-4.7

# ----------------------------------------
# 可选配置
# ----------------------------------------

# 温度参数（默认: 0.7，范围: 0.0-2.0）
# AURAI_TEMPERATURE=0.7

# 对话历史最大保存数（默认: 50）
# AURAI_MAX_HISTORY=50

# ----------------------------------------
# Token 配置（默认基于 GLM-4.7，可根据模型调整）
# ----------------------------------------
# 以下配置使用 GLM-4.7 的优化值作为默认，使用其他模型时可调整：

# 模型上下文窗口大小（tokens）
# 默认: 200000 (基于 GLM-4.7)
# 根据您的模型调整：
# - GLM-4.7: 200000
# - Claude 3.5 Sonnet: 200000
# - GPT-4o: 128000
# - DeepSeek: 64000
# AURAI_CONTEXT_WINDOW=200000

# 单条消息最大tokens（用于文件分批发送）
# 默认: 150000 (基于 GLM-4.7 优化)
# 建议设置为上下文窗口的 70-80%
# AURAI_MAX_MESSAGE_TOKENS=150000

# 最大输出tokens（上级 AI 的回复长度）
# 默认: 32000 (基于 GLM-4.7 优化)
# 根据需要调整：更大的值可获得更长的分析回复
# AURAI_MAX_TOKENS=32000

# ----------------------------------------
# 服务器配置（通常无需修改）
# ----------------------------------------

# 服务器日志级别（默认: INFO）
# AURAI_LOG_LEVEL=INFO

# 启用对话历史持久化（默认: true）
# AURAI_ENABLE_PERSISTENCE=true

# 对话历史文件路径（默认: ~/.mcp-aurai/history.json）
# AURAI_HISTORY_PATH=~/.mcp-aurai/history.json
